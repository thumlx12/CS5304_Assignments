{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "BATCH_SIZE = 1000\n",
    "LR = 3e-3\n",
    "n_factor = 4\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trains = ['ml-10M100K/r1.train','ml-10M100K/r2.train','ml-10M100K/r3.train','ml-10M100K/r4.train','ml-10M100K/r5.train']\n",
    "tests = ['ml-10M100K/r1.test','ml-10M100K/r2.test','ml-10M100K/r3.test','ml-10M100K/r4.test','ml-10M100K/r5.test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df_trains =[pd.read_csv(t, sep='::', names=names,engine='python') for t in trains]\n",
    "df_tests = [pd.read_csv(t, sep='::', names=names,engine='python') for t in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_arr = [get_movielens_ratings(df) for df in df_trains]\n",
    "ratings_arr_test = [get_movielens_ratings(df) for df in df_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size,ratings):\n",
    "    # Sort our data and scramble it\n",
    "    rows, cols = ratings.shape\n",
    "    p = np.random.permutation(rows)\n",
    "    \n",
    "    # create batches\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < rows:\n",
    "        batch = p[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= rows:\n",
    "        batch = range(sindex,rows)\n",
    "        yield batch\n",
    "        \n",
    "def get_batch_in_seqence(batch_size, ratings):\n",
    "    rows, cols = ratings.shape\n",
    "    # create batches\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < rows:\n",
    "        batch = range(sindex,eindex)\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    if eindex >= rows:\n",
    "        batch = range(sindex,rows)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, batch_size, ratings, loss_func, reg_loss_func):\n",
    "    epoch_ave_loss = 0.0\n",
    "    batch_cnt = 0\n",
    "    for i,batch in enumerate(get_batch(batch_size, ratings)):\n",
    "        # Set gradients to zero\n",
    "        reg_loss_func.zero_grad()\n",
    "        \n",
    "        # Turn data into variables\n",
    "        interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "        rows = Variable(torch.LongTensor(batch))\n",
    "        cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "        if use_gpu:\n",
    "            interactions = interactions.cuda()\n",
    "            rows = rows.cuda()\n",
    "            cols = cols.cuda()\n",
    "    \n",
    "        # Predict and calculate loss\n",
    "        predictions = model(rows, cols)\n",
    "        loss = loss_func(predictions, interactions)\n",
    "        epoch_ave_loss += loss.data[0]\n",
    "        batch_cnt += 1\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update the parameters\n",
    "        reg_loss_func.step()\n",
    "        \n",
    "    return model, epoch_ave_loss/batch_cnt\n",
    "\n",
    "def run_test_batchly(model, ratings, loss_func, batch_size=1000):\n",
    "    for i,batch in enumerate(get_batch_in_seqence(batch_size, ratings)):\n",
    "        # Turn data into variables\n",
    "        interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "        rows = Variable(torch.LongTensor(batch))\n",
    "        cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "        if use_gpu:\n",
    "            interactions = interactions.cuda()\n",
    "            rows = rows.cuda()\n",
    "            cols = cols.cuda()\n",
    "        # Predict and calculate loss\n",
    "        predictions = model(rows, cols)\n",
    "        loss = loss_func(predictions, interactions)\n",
    "        yield predictions, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, ratings, weight_decay, num_epochs=25, batch_size=1000):\n",
    "    reg_loss_func = torch.optim.SGD(model.parameters(), lr = 3e-3, weight_decay = weight_decay)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    lowest_loss = 1e10\n",
    "    print('Epoch\\tAve-loss')\n",
    "    for epoch in range(num_epochs):\n",
    "        model, ave_loss = run_epoch(model, batch_size, ratings, loss_func, reg_loss_func)\n",
    "        print('{}\\t{}'.format(epoch, ave_loss))\n",
    "        if lowest_loss > ave_loss:\n",
    "            lowest_loss = ave_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):    \n",
    "    def __init__(self, n_users, n_items, n_factors=4):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors, sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors, sparse=False)\n",
    "        if use_gpu:\n",
    "            self.user_factors = self.user_factors.cuda()\n",
    "            self.item_factors = self.item_factors.cuda()\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "    \n",
    "    # For convenience when we want to predict a sinble user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factors\n",
    "        return (pred + self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "        # Need to fit bias factors\n",
    "        return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiasedMatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=4):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors, sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors, sparse=False)\n",
    "        self.item_biases = torch.nn.Embedding(n_items, 1, sparse=False)\n",
    "        if use_gpu:\n",
    "            self.user_factors = self.user_factors.cuda()\n",
    "            self.item_factors = self.item_factors.cuda()\n",
    "            self.item_biases = self.item_biases.cuda()\n",
    "        \n",
    "    def forward(self, users, items):\n",
    "        constant_user_biases = Variable(torch.FloatTensor(np.transpose([np.ones(len(users))])))\n",
    "        if use_gpu:\n",
    "            constant_user_biases = constant_user_biases.cuda()\n",
    "        biases = torch.mm(constant_user_biases, torch.transpose(self.item_biases(items),0,1))\n",
    "        linear = torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "        return biases + linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset:0, weight_decay:0.001\n",
      "Epoch\tAve-loss\n",
      "0\t4.014335456821653\n",
      "1\t4.013113492065006\n",
      "2\t4.007376299964057\n",
      "3\t4.006175494856304\n",
      "4\t3.9995601375897727\n",
      "5\t3.998066249820921\n",
      "6\t3.9943118029170566\n",
      "7\t3.9897547231780157\n",
      "8\t3.9877712263001337\n",
      "9\t3.9834243191613092\n",
      "10\t3.9808948834737143\n",
      "11\t3.9740902649031744\n",
      "12\t3.97379493382242\n",
      "13\t3.969550155931049\n",
      "14\t3.966994331942664\n",
      "15\t3.9635450177722507\n",
      "16\t3.9581759638256497\n",
      "17\t3.9558136694961124\n",
      "18\t3.9526692661974163\n",
      "19\t3.9469648467169867\n",
      "20\t3.9446189370420246\n",
      "21\t3.9429165754053326\n",
      "22\t3.9367858204576702\n",
      "23\t3.9338105387157865\n",
      "24\t3.9327875640657215\n",
      "25\t3.9262405269675784\n",
      "26\t3.922848857111401\n",
      "27\t3.921896424558428\n",
      "28\t3.9169916411240897\n",
      "29\t3.9146319097942777\n",
      "30\t3.909904337591595\n",
      "31\t3.906446543004778\n",
      "32\t3.9030089808834925\n",
      "33\t3.8988591167661877\n",
      "34\t3.8971494999196796\n",
      "35\t3.892407202058368\n",
      "36\t3.8900917801592083\n",
      "37\t3.88582307100296\n",
      "38\t3.880741665760676\n",
      "39\t3.8800672226481967\n",
      "40\t3.875399592849943\n",
      "41\t3.873704820871353\n",
      "42\t3.8691502842638226\n",
      "43\t3.8662931554847293\n",
      "44\t3.8616203831301794\n",
      "45\t3.8577758272488913\n",
      "46\t3.8551825417412653\n",
      "47\t3.852991157107883\n",
      "48\t3.847823941045337\n",
      "49\t3.8455717265605927\n",
      "trainset:0, weight_decay:0.01\n",
      "Epoch\tAve-loss\n",
      "0\t3.9997464451524944\n",
      "1\t3.9650985399881997\n",
      "2\t3.930801080332862\n",
      "3\t3.8976568480332694\n",
      "4\t3.863788730568356\n",
      "5\t3.83164835969607\n",
      "6\t3.7969129516018763\n",
      "7\t3.7642055087619357\n",
      "8\t3.7346551020940146\n",
      "9\t3.700496388806237\n",
      "10\t3.668621096346113\n",
      "11\t3.637464086214701\n",
      "12\t3.6055308414830103\n",
      "13\t3.574837972720464\n",
      "14\t3.5443113247553506\n",
      "15\t3.51472998658816\n",
      "16\t3.485695789257685\n",
      "17\t3.455436991320716\n",
      "18\t3.4249589112069874\n",
      "19\t3.3951217300362058\n",
      "20\t3.3654119306140475\n",
      "21\t3.3382765220271216\n",
      "22\t3.308206230401993\n",
      "23\t3.2796756989426084\n",
      "24\t3.251611010895835\n",
      "25\t3.2247935599750943\n",
      "26\t3.196165439155367\n",
      "27\t3.169667614830865\n",
      "28\t3.141523735390769\n",
      "29\t3.1168289449479847\n",
      "30\t3.08782888452212\n",
      "31\t3.0614475905895233\n",
      "32\t3.0348647369278803\n",
      "33\t3.0106116003460355\n",
      "34\t2.9845404989189572\n",
      "35\t2.957520090871387\n",
      "36\t2.932700743277868\n",
      "37\t2.9077635771698422\n",
      "38\t2.884590460194482\n",
      "39\t2.8596137199136944\n",
      "40\t2.8345432612631054\n",
      "41\t2.8100826707151203\n",
      "42\t2.7855754792690277\n",
      "43\t2.7625536488162146\n",
      "44\t2.738689962360594\n",
      "45\t2.7153358856836953\n",
      "46\t2.6922956307729087\n",
      "47\t2.6692151957088046\n",
      "48\t2.646291093693839\n",
      "49\t2.623997539281845\n",
      "trainset:0, weight_decay:0.1\n",
      "Epoch\tAve-loss\n",
      "0\t3.84490919775433\n",
      "1\t3.5281376706229315\n",
      "2\t3.2377478380997977\n",
      "3\t2.971378415822983\n",
      "4\t2.7276005844275155\n",
      "5\t2.5039052267869315\n",
      "6\t2.29873224761751\n",
      "7\t2.1109427677260504\n",
      "8\t1.9354212548997667\n",
      "9\t1.7791399889522128\n",
      "10\t1.6331987960471048\n",
      "11\t1.4997604075405333\n",
      "12\t1.3777446630928252\n",
      "13\t1.2654730545149908\n",
      "14\t1.1628088653087616\n",
      "15\t1.0681330131159887\n",
      "16\t0.9817142229941156\n",
      "17\t0.9026310841242472\n",
      "18\t0.8291236071123017\n",
      "19\t0.7628039419651031\n",
      "20\t0.7017001236478487\n",
      "21\t0.645215157005522\n",
      "22\t0.5941588381926218\n",
      "23\t0.546510347061687\n",
      "24\t0.5032205594082674\n",
      "25\t0.46334099190102684\n",
      "26\t0.42706693667504525\n",
      "27\t0.3936186693608761\n",
      "28\t0.3630414700342549\n",
      "29\t0.334859874099493\n",
      "30\t0.30916110798716545\n",
      "31\t0.28545014436046284\n",
      "32\t0.26376025854713386\n",
      "33\t0.24385089923938116\n",
      "34\t0.2254789931078752\n",
      "35\t0.20872891652915213\n",
      "36\t0.19338332696093452\n",
      "37\t0.1793688949611452\n",
      "38\t0.1663900019807948\n",
      "39\t0.15452459330360094\n",
      "40\t0.1437084914909469\n",
      "41\t0.13370092999604014\n",
      "42\t0.12455397326913145\n",
      "43\t0.11619898956269026\n",
      "44\t0.10843569702572292\n",
      "45\t0.10139190478043424\n",
      "46\t0.0948931924584839\n",
      "47\t0.08897019343243705\n",
      "48\t0.08352524021433459\n",
      "49\t0.07855966397457653\n"
     ]
    }
   ],
   "source": [
    "models_without_biases = {}\n",
    "for i in range(5):\n",
    "    ratings = ratings_arr[i]\n",
    "    user_num, item_num = ratings.shape\n",
    "    for weight_decay in [0.001, 0.01, 0.1]:\n",
    "        print('trainset:{}, weight_decay:{}'.format(i, weight_decay))\n",
    "        model = MatrixFactorization(user_num, item_num, 4)\n",
    "        if use_gpu:\n",
    "            model = model.cuda()\n",
    "        model = train_model(model, ratings, weight_decay, EPOCH)\n",
    "        model_name = str(i)+ '_' + str(weight_decay)\n",
    "        models_without_biases[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset:0, weight_decay:0.1\n",
      "Epoch\tAve-loss\n",
      "0\t4.059445771906111\n",
      "1\t3.6979528963565826\n",
      "2\t3.3670172227753534\n",
      "3\t3.0732666320270963\n",
      "4\t2.8104589647716947\n",
      "5\t2.5801185535060034\n",
      "6\t2.3781093491448297\n",
      "7\t2.2042880058288574\n",
      "8\t2.0415328989426293\n",
      "9\t1.8652843882640202\n",
      "10\t1.7000817822085486\n",
      "11\t1.5489957862430148\n",
      "12\t1.419359490275383\n",
      "13\t1.3030792209837172\n",
      "14\t1.2018069856696658\n",
      "15\t1.113113209605217\n",
      "16\t1.0334666222333908\n",
      "17\t0.9463949427008629\n",
      "18\t0.8626923668715689\n",
      "19\t0.7884290582603879\n",
      "20\t0.7226263135671616\n",
      "21\t0.6630616585413615\n",
      "22\t0.611938490635819\n",
      "23\t0.5666840531759791\n",
      "24\t0.5277889515790675\n",
      "25\t0.48597100501259166\n",
      "26\t0.444123783459266\n",
      "27\t0.40679725093974006\n",
      "28\t0.3728519131739934\n",
      "29\t0.3431900545126862\n",
      "30\t0.3168380219075415\n",
      "31\t0.29377154509226483\n",
      "32\t0.2737815073794789\n",
      "33\t0.2550428097860681\n",
      "34\t0.2343995649781492\n",
      "35\t0.21525708730849955\n",
      "36\t0.1983705283039146\n",
      "37\t0.18298570811748505\n",
      "38\t0.1695170599139399\n",
      "39\t0.15746413088507122\n",
      "40\t0.14687482433186638\n"
     ]
    }
   ],
   "source": [
    "models_with_biases = {}\n",
    "for i in range(5):\n",
    "    ratings = ratings_arr[i]\n",
    "    user_num, item_num = ratings.shape\n",
    "    for weight_decay in [0.1, 0.01, 0.001]:\n",
    "        print('trainset:{}, weight_decay:{}'.format(i, weight_decay)) \n",
    "        model = BiasedMatrixFactorization(user_num, item_num, 4)\n",
    "        if use_gpu:\n",
    "            model = model.cuda()\n",
    "        model = train_model(model, ratings, weight_decay, EPOCH)\n",
    "        model_name = str(i)+ '_' + str(weight_decay)\n",
    "        models_with_biases[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lm769\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:159: UserWarning: Couldn't retrieve source code for container of type BiasedMatrixFactorization. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\lm769\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:159: UserWarning: Couldn't retrieve source code for container of type MatrixFactorization. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "for item in models_with_biases.items():\n",
    "    torch.save(item[1],'model/with_biases_'+str(item[0]))\n",
    "    \n",
    "for item in models_without_biases.items():\n",
    "    torch.save(item[1],'model/without_biases_'+str(item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_getDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2d5dd6f11edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbias_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/r1_with_bias_0.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assign5_r5results.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu_ids_in_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_test_batchly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_arr_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[0;32m--> 389\u001b[0;31m                     data_type(size), location)\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_getDevice'"
     ]
    }
   ],
   "source": [
    "\n",
    "rst = open('assign5_r5results.tsv','w')\n",
    "u_ids_in_test = set(df_tests[4].user_id.unique())\n",
    "user_id = 1\n",
    "for pred, loss in run_test_batchly(bias_model, ratings_arr_test[4], torch.nn.MSELoss()):\n",
    "    for user in pred:\n",
    "        if base_id %10000 == 0: \n",
    "            print(base_id)\n",
    "        tops = torch.topk(user,50)[1].data.cpu().numpy()\n",
    "        recs = np.setdiff1d(tops, np.array(ratings_arr_test[4].rows[user_id-1]), assume_unique=True)\n",
    "        if len(recs) < 5:\n",
    "            print('ERROR!!!\\t', base_id)\n",
    "        if user_id in u_ids_in_test:\n",
    "            recs = recs[:5]\n",
    "            rst.write(str(user_id) + '\\t' + '\\t'.join([str(rec) for rec in recs]) + '\\n')\n",
    "        base_id += 1\n",
    "rst.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
